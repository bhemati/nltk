{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for all exercises\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import movie_reviews\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a name gender classifier using the Names Corpus, the `apply_features` function, shuffling, and a test set of 500 instances. Use the following features:\n",
    "\n",
    "a) first letter;  \n",
    "b) last letter;  \n",
    "c) last two letters;  \n",
    "d) length;  \n",
    "e) for each letter one feature, which is true if the name contains the letter.\n",
    "\n",
    "Use the `NaiveBayesClassifier`, calculate the accuracy, and display the 10 most informative features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"last_two_letters\"] = name[-2].lower()\n",
    "    features[\"length\"] = len(name)\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(labeled_names)\n",
    "featuresets = [(apply_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     38.3 : 1.0\n",
      "             last_letter = 'k'              male : female =     31.2 : 1.0\n",
      "             last_letter = 'f'              male : female =     27.7 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.9 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.2 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.5 : 1.0\n",
      "             last_letter = 'm'              male : female =      9.0 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.7 : 1.0\n",
      "        last_two_letters = 'o'              male : female =      7.6 : 1.0\n",
      "             last_letter = 'r'              male : female =      7.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(apply_features(\"Behrad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. Using this dataset, build a `NaiveBayesClassifier` that predicts the correct sense tag for a given instance for the word \"hard\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_features(inst):\n",
    "    features = {}\n",
    "    p = inst.position\n",
    "    features[\"previous\"] = inst.context[p-1]\n",
    "    features[\"next\"] = inst.context[p+1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9168591224018475\n",
      "0.9122401847575058\n",
      "0.9168591224018475\n",
      "0.9168591224018475\n",
      "0.9053117782909931\n",
      "0.8868360277136259\n",
      "0.9168591224018475\n",
      "0.9214780600461894\n",
      "0.9053117782909931\n",
      "0.8891454965357968\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import senseval\n",
    "instances = senseval.instances('hard.pos')\n",
    "labeled_instances = [(inst, inst.senses) for inst in instances]\n",
    "size = int(len(labeled_instances) * 0.1)\n",
    "accuracy_t = 0\n",
    "for i in range(10):\n",
    "    random.shuffle(labeled_instances)\n",
    "    featuresets = [(apply_features(w), sense) for (w, sense) in labeled_instances]\n",
    "    train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    accuracy_t += accuracy\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087759815242494"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_t/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the preceding and following word as features. They can be calculated by retrieving the position of the word \"hard\" as `p=inst.position` and then accessing `inst.context[p-1]` and `inst.context[p+1]`.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The synonyms \"strong\" and \"powerful\" pattern differently. Use the tagged Brown corpus with the universal tagset to first list the nouns which follow \"strong\" vs. \"powerful\". Write for this a function `next_noun(word, tagged_text)` which returns the list of nouns that follow `word` in the `tagged_text`. Build then a `NaiveBayesClassifier` that predicts when each word should be used by using the function `apply_features` and the following noun as single feature.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_noun(word, tagged_text):\n",
    "    return sorted(set([tagged_text[i+1][0].lower() for i, (w, t) \n",
    "                       in enumerate(tagged_text) if w.lower()==word \n",
    "                       and tagged_text[i+1][1] == \"NOUN\"]))\n",
    "\n",
    "def apply_features(word):\n",
    "    features = {}\n",
    "    features['next_noun'] = word\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636363636364\n",
      "0.6363636363636364\n",
      "0.6363636363636364\n",
      "0.6363636363636364\n",
      "0.7272727272727273\n",
      "0.5454545454545454\n",
      "0.7272727272727273\n",
      "0.6363636363636364\n",
      "0.5454545454545454\n",
      "0.7272727272727273\n",
      "total:  0.6454545454545454\n"
     ]
    }
   ],
   "source": [
    "tagged_text = brown.tagged_words(tagset='universal')\n",
    "strong = next_noun('strong', tagged_text)\n",
    "powerful = next_noun('powerful', tagged_text)\n",
    "labeled_instances = ([(w, 'strong') for w in strong] +\n",
    "[(w, 'powerful') for w in powerful])\n",
    "size = int(len(labeled_instances) * 0.1)\n",
    "accuracy_t = 0\n",
    "for i in range(10):\n",
    "    random.shuffle(labeled_instances)\n",
    "    featuresets = [(apply_features(w), w[1]) for w in labeled_instances]\n",
    "    train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    accuracy_t += accuracy\n",
    "    print(accuracy)\n",
    "print('total: ', accuracy_t/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Based on the Movie Reviews document classifier discussed in this chapter, build a new `NaiveBayesClassifier`. Tag first the Movie Reviews Corpus using the combined tagger from the previous chapter stored in `t2.pkl`. Filter the tagged words to contain only words for the tags `['JJ', 'JJR', 'JJS', 'RB', 'NN', 'NNS', 'VB', 'VBN', 'VBG', 'VBZ', 'VBD', 'QL']` as well as only alphabetic tokens with at least three characters. Convert the words to lowercase. Use the most common 5000 words as `word_features` in the function `document_features`. \n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the accuracy and 5 most informative features for each iteration. Finally, print the average accuracy.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   contains(magnificent) = True              pos : neg    =     11.4 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     11.0 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     11.0 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.7 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.3 : 1.0\n",
      "accuracy 0 0.84\n",
      "Most Informative Features\n",
      "   contains(magnificent) = True              pos : neg    =     11.4 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     11.0 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     11.0 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.7 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.3 : 1.0\n",
      "Most Informative Features\n",
      "      contains(depicted) = True              pos : neg    =     12.9 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     11.3 : 1.0\n",
      "        contains(elliot) = True              pos : neg    =     10.9 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.7 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.7 : 1.0\n",
      "accuracy 1 0.77\n",
      "Most Informative Features\n",
      "      contains(depicted) = True              pos : neg    =     12.9 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     11.3 : 1.0\n",
      "        contains(elliot) = True              pos : neg    =     10.9 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.7 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.7 : 1.0\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.8 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.3 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.2 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.1 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =      9.7 : 1.0\n",
      "accuracy 2 0.85\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.8 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.3 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.2 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.1 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =      9.7 : 1.0\n",
      "Most Informative Features\n",
      "    contains(schumacher) = True              neg : pos    =     12.5 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.9 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.8 : 1.0\n",
      "        contains(elliot) = True              pos : neg    =     10.2 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.0 : 1.0\n",
      "accuracy 3 0.81\n",
      "Most Informative Features\n",
      "    contains(schumacher) = True              neg : pos    =     12.5 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.9 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.8 : 1.0\n",
      "        contains(elliot) = True              pos : neg    =     10.2 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.0 : 1.0\n",
      "Most Informative Features\n",
      "        contains(seagal) = True              neg : pos    =     13.7 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     11.0 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.6 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.6 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.5 : 1.0\n",
      "accuracy 4 0.76\n",
      "Most Informative Features\n",
      "        contains(seagal) = True              neg : pos    =     13.7 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     11.0 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.6 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.6 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.5 : 1.0\n",
      "Most Informative Features\n",
      "     contains(ludicrous) = True              neg : pos    =     14.1 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.9 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.4 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.0 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =      9.9 : 1.0\n",
      "accuracy 5 0.77\n",
      "Most Informative Features\n",
      "     contains(ludicrous) = True              neg : pos    =     14.1 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.9 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.4 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.0 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =      9.9 : 1.0\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.1 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.9 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.6 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.1 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =      9.6 : 1.0\n",
      "accuracy 6 0.78\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.1 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.9 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.6 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.1 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =      9.6 : 1.0\n",
      "Most Informative Features\n",
      "        contains(seagal) = True              neg : pos    =     13.7 : 1.0\n",
      "     contains(stupidity) = True              neg : pos    =     12.2 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     11.2 : 1.0\n",
      "        contains(elliot) = True              pos : neg    =     11.0 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.6 : 1.0\n",
      "accuracy 7 0.87\n",
      "Most Informative Features\n",
      "        contains(seagal) = True              neg : pos    =     13.7 : 1.0\n",
      "     contains(stupidity) = True              neg : pos    =     12.2 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     11.2 : 1.0\n",
      "        contains(elliot) = True              pos : neg    =     11.0 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.6 : 1.0\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.6 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.6 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.5 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.2 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.1 : 1.0\n",
      "accuracy 8 0.82\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.6 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.6 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.5 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.2 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.1 : 1.0\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.2 : 1.0\n",
      "     contains(stupidity) = True              neg : pos    =     12.2 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     11.0 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.7 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.4 : 1.0\n",
      "accuracy 9 0.87\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.2 : 1.0\n",
      "     contains(stupidity) = True              neg : pos    =     12.2 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     11.0 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.7 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.4 : 1.0\n",
      "total:  0.8140000000000001\n"
     ]
    }
   ],
   "source": [
    "tags = ['JJ', 'JJR', 'JJS', 'RB', 'NN', 'NNS', 'VB', 'VBN', 'VBG', 'VBZ', 'VBD', 'QL']\n",
    "input = open('t2.pkl', 'rb')\n",
    "t2 = load(input)\n",
    "input.close()\n",
    "def apply_tagger(tagger, corpus):\n",
    "    return tagger.tag(corpus)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "words = movie_reviews.words()\n",
    "words_fd = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "tagged = apply_tagger(t2, words)\n",
    "tagged_f = [(w.lower(),t) for (w,t) in tagged if t in tags and len(w)>=3 and w.isalpha()]\n",
    "words_fd = nltk.FreqDist(w.lower() for (w,t) in tagged_f)\n",
    "word_features = list(words_fd)[:5000]\n",
    "def document_features(document): \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "accuracy_t = 0\n",
    "for i in range (10):\n",
    "    random.shuffle(documents)\n",
    "    featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "    train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    accuracy_t += accuracy\n",
    "    classifier.show_most_informative_features(5)\n",
    "    print('accuracy {}'.format(i), accuracy)\n",
    "    classifier.show_most_informative_features(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  0.8140000000000001\n"
     ]
    }
   ],
   "source": [
    "print('total: ', accuracy_t/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "The PP Attachment Corpus is a corpus describing prepositional phrase attachment decisions. Each instance in the training corpus is encoded as a `PPAttachment` object:\n",
    "\n",
    "    from nltk.corpus import ppattach\n",
    "    ppattach.attachments('training')\n",
    "    \n",
    "        [PPAttachment(sent='0', verb='join', noun1='board',\n",
    "            prep='as', noun2='director', attachment='V'),\n",
    "        PPAttachment(sent='1', verb='is', noun1='chairman',\n",
    "            prep='of', noun2='N.V.', attachment='N'),\n",
    "        ...]\n",
    "\n",
    "    inst = ppattach.attachments('training')[1]\n",
    "    (inst.noun1, inst.prep, inst.noun2)\n",
    "    \n",
    "        ('chairman', 'of', 'N.V.')\n",
    "\n",
    "In the same way, `ppattach.attachments('test')` accesses the test instances. Select only the instances where `inst.attachment` is `'N'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import ppattach\n",
    "nattach = [inst for inst in ppattach.attachments('training')\n",
    "               if inst.attachment == 'N']\n",
    "nattach_test = [inst for inst in ppattach.attachments('test')\n",
    "               if inst.attachment == 'N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this sub-corpus, build a `NaiveBayesClassifier` that attempts to predict which preposition is used to connect a given pair of nouns. For example, given the pair of nouns \"team\" and \"researchers\", the classifier should predict the preposition \"of\". \n",
    "\n",
    "Write for this purpose a function `prepare_featuresets(subcorpus)`, where `subcorpus` is either the string \"training\" or \"test\" to return the training set or the test set. \n",
    "\n",
    "Print the achieved accuracy as well as the result of `classifier.classify({ 'noun1': 'team', 'noun2': 'researchers' })`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_featuresets(subcorpus):\n",
    "    features = {}\n",
    "    tr_set, te_set = [], []\n",
    "    if subcorpus == 'training':\n",
    "        for inst in nattach:\n",
    "            features['noun1'] = inst.noun1\n",
    "            features['noun2'] = inst.noun2\n",
    "            label = inst.prep\n",
    "            tr_set.append((features.copy(), label))\n",
    "        return tr_set\n",
    "    elif subcorpus == 'test':\n",
    "        for inst in nattach_test:\n",
    "            features['noun1'] = inst.noun1\n",
    "            features['noun2'] = inst.noun2\n",
    "            label = inst.prep\n",
    "            te_set.append((features.copy(), label))\n",
    "        return te_set\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = prepare_featuresets('training')\n",
    "test_set = prepare_featuresets('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   noun1 = 'stake'            in : of     =     75.0 : 1.0\n",
      "                   noun2 = 'million'          of : with   =     57.5 : 1.0\n",
      "                   noun1 = '%'                of : for    =     53.5 : 1.0\n",
      "                   noun1 = 'questions'     about : of     =     46.0 : 1.0\n",
      "                   noun1 = 'interest'         in : of     =     34.3 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5690032858707558"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "classifier.show_most_informative_features(5)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify({ 'noun1': 'team', 'noun2': 'researchers' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk_venv",
   "language": "python",
   "name": "nltk_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
