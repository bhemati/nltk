{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk.corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6e6b1319e74a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgutenberg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk.corpus'"
     ]
    }
   ],
   "source": [
    "#imports for all exercises\n",
    "import pprint\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import networkx as nx\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import memoize\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a program to initialize a two-dimensional array of sets called `word_vowels` and process a list of words, adding each word to `word_vowels[l][v]` where $l$ is the length of the word and $v$ is the number of vowels it contains. Test your program with a 10x10-array and the list `['Alice', 'hat', 'heute', 'ihren', 'freien', 'Tag']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['Alice', 'hat', 'heute', 'ihren', 'freien', 'Tag']\n",
    "vowels = [[v for v in word if v in 'aeiou'] for word in words]\n",
    "word_vowels = []\n",
    "for (l,v) in zip(words, vowels):\n",
    "    word_vowels.append([len(l), len(v)])\n",
    "\n",
    "word_vowels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Write a program that prints all words that only appear in the last 10\\% of a text. Test your code with the file `'shakespeare-macbeth.txt'` from the Gutenberg Corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_last_10(text):\n",
    "    cut = int(0.9 * len(text))\n",
    "    return text[cut:]\n",
    "text = gutenberg.words()\n",
    "print(return_last_10(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Write a program that takes a sentence expressed as a single string, splits it and counts up the words. Get it to print out each word and the word's frequency, one per line, in alphabetical order. Test it with the sentence: `'das ist heute wieder einmal wirklich ein sehr schöner tag das kann ich dir wieder einmal sagen'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_freq(raw):\n",
    "    text = sorted(nltk.word_tokenize(raw))\n",
    "    count = len(text)\n",
    "    return dict(nltk.FreqDist(text))\n",
    "\n",
    "raw = 'das ist heute wieder einmal wirklich ein sehr schöner tag das kann ich dir wieder einmal sagen'\n",
    "text_freq(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Write a function `sort_dist(candidates, target)`. The `candidates` are a list of strings representing WordNet synset names, and `target` a synset name string. The function shall sort the `candidates` for proximity to the `target` synset using `shortest_path_distance()`. \n",
    "\n",
    "Test your function with `candidates=['minke_whale.n.01','orca.n.01','novel.n.01', 'tortoise.n.01']` and `target='right_whale.n.01'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dist(candidates, target):\n",
    "    target = wn.synset(target)\n",
    "    dic = {candidate:target.shortest_path_distance(wn.synset(candidate)) \n",
    "    for candidate in candidates}\n",
    "    return dict(sorted(dic.items(), key=lambda item: item[1]))\n",
    "\n",
    "candidates=['minke_whale.n.01','orca.n.01','novel.n.01', 'tortoise.n.01']\n",
    "target='right_whale.n.01'\n",
    "sort_dist(candidates, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Write a recursive function `lookup(trie, key)` that looks up a `key` in a `trie`, and returns the value it finds. The function should cover the following cases:\n",
    "\n",
    "a) it should return a corresponding message if the key is not included in the trie;  \n",
    "b) it should return a message if the key is not unique, i.e. if there are several words for this prefix;  \n",
    "c) if a word is uniquely determined by the key prefix it should be returned as result. \n",
    "\n",
    "Try your function for the following trie and test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value\n",
    "\n",
    "trie = {}\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "insert(trie, 'cheval','horse') \n",
    "trie = dict(trie)             \n",
    "pprint.pprint(trie, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(trie, key):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            return 'key not included'\n",
    "        return lookup(trie[first], rest)\n",
    "    elif len(trie) > 1:\n",
    "        return 'not unique'\n",
    "    elif 'value' in trie.keys():\n",
    "        return trie['value']\n",
    "    else:\n",
    "        while ('value' not in trie.keys()):\n",
    "            [[ _,trie ]] = trie.items() # not so elegant way of reducing trie\n",
    "        return trie['value']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lookup(trie, 'chat'))\n",
    "print(lookup(trie, 'cha'))\n",
    "print(lookup(trie, 'souris'))\n",
    "print(lookup(trie, 'cheval'))\n",
    "print(lookup(trie, 'che'))\n",
    "print(lookup(trie, 'chev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Write a recursive function `pp_trie` that pretty prints a trie in alphabetically sorted order by replacing common prefixes with `'-'` characters.\n",
    "Test your implementation with the following example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = {}\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'souris', 'mouse')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "insert(trie, 'cheval','horse') \n",
    "trie = dict(trie)             \n",
    "pprint.pprint(trie, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with help from stackoverflow\n",
    "def pp_trie(trie, s = \"\"):\n",
    "    first = True\n",
    "    for k, v in sorted(trie.items(), key = lambda x: x[0]):\n",
    "        if isinstance(v, dict):\n",
    "            if first:\n",
    "                prefix = s + k\n",
    "                first = False\n",
    "            else:\n",
    "                prefix = '-'*len(s) + k\n",
    "            pp_trie(v, prefix)\n",
    "        else:\n",
    "            stuff = s + \": \" + v\n",
    "            pprint.pprint(stuff, width=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_trie(trie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    chair: flesh\n",
    "    ---t: cat\n",
    "    --eval: horse\n",
    "    --ic: stylish\n",
    "    ---en: dog\n",
    "    souris: mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "The *Catalan numbers* arise in many applications of combinatorial mathematics, including the counting of parse trees. The series can be defined as follows: $C_0 = 1$, and $C_{n+1} = \\sum_{i=0}^{n}C_iC_{n-i}$ for $n\\geq{0}$.\n",
    "\n",
    "Write:\n",
    "\n",
    "a) a recursive function `cn(n)` to compute the $n$th Catalan number $C_{n}$,  \n",
    "b) a corresponding function `cn2(n)` that uses dynamic programming by storing calculated solutions in a lookup table,  \n",
    "c) a function `cn3(n)`, which is identical to `cn(n)` but uses a `memoize` decorator.\n",
    "\n",
    "Test your functions first by calculating the Catalan numbers $C_0\\dots C_{16}$ and then by using the `timeit` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cn(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return sum([cn(i)*cn(n-1-i) for i in range(n)])\n",
    "\n",
    "def cn2(n):\n",
    "    C = [0 for i in range(n+1)]\n",
    "    C[0] = 1\n",
    "    for i in range(1,n+1):\n",
    "        C[i] = sum([C[j]*C[i-j-1] for j in range(i)])\n",
    "    return C[n]\n",
    "\n",
    "@memoize\n",
    "def cn3(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return sum([cn(i)*cn(n-1-i) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('recursive: ', timeit.timeit(\"cn(16)\", setup=\"from __main__ import cn\", number=5))\n",
    "print('DP: ', timeit.timeit(\"cn2(16)\", setup=\"from __main__ import cn2\", number=5))\n",
    "print('memoize:', timeit.timeit(\"cn3(16)\", setup=\"from __main__ import cn3\", number=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk_venv",
   "language": "python",
   "name": "nltk_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
